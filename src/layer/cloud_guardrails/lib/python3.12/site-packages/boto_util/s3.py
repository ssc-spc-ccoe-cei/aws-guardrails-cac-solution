import logging
import re

import botocore.exceptions

logger = logging.getLogger()
logger.setLevel(logging.INFO)


def extract_bucket_name_and_key(object_path: str) -> tuple[str, str]:
    match = re.match(r"s3:\/\/([^/]+)\/((?:[^/]*/)*.*)", object_path)
    if match:
        bucket_name = match.group(1)
        key_name = match.group(2)
    else:
        logger.error("Unable to parse S3 object path %s", object_path)
        raise ValueError(f"Unable to parse S3 object path {object_path}")
    return bucket_name, key_name


def check_s3_object_exists(s3_client, object_path: str) -> bool:
    """
    Check if the S3 object exists

    Keyword arguments:

    s3_client -- the S3 client to use to query for the object

    object_path -- the S3 object path
    """
    bucket_name, key_name = extract_bucket_name_and_key(object_path)
    try:
        s3_client.head_object(Bucket=bucket_name, Key=key_name)
    except botocore.exceptions.ClientError as err:
        if err.response["Error"]["Code"] == "404":
            logger.info("Object %s not found in bucket %s", key_name, bucket_name)
            return False
        elif err.response["Error"]["Code"] == "403":
            logger.info("Access denied to bucket %s", bucket_name)
            return False
        else:
            logger.error("Error trying to find object %s in bucket %s", key_name, bucket_name)
            raise ValueError(f"Error trying to find object {key_name} in bucket {bucket_name}") from err
    else:
        return True


def read_s3_object(s3_client, object_path: str, encoding: str = "utf-8") -> str:
    bucket, key = extract_bucket_name_and_key(object_path)
    response = s3_client.get_object(Bucket=bucket, Key=key)
    file_contents = response.get("Body").read().decode(encoding)
    return file_contents


def get_lines_from_s3_file(s3_client, object_path: str, encoding: str = "utf-8") -> list[str]:
    return read_s3_object(s3_client, object_path, encoding).splitlines()
